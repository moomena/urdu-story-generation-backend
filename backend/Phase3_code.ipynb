{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generated Story 1 ---\n",
      "تو بابا مجھے اپنا حصہ دار سے ان کے حواس پر قابو کرتی کی ہم بڑی خرابی کی شادیاں سوہنے گھبروجوان تنہائی۔ کرتے ہیں جو اپنی تین جا رہا تھا مجھے پریشانی ہورہی ہیں پہ نہیں بولا۔ بس ذرا لڑائی جھگڑے فساد سے نکل حیرت سے اپنے گھر کے مارے ہلکی سی ٹوٹی ہوئی میں نے بتایا تھا گھر میں استانی۔ ہمارے لئے قائم کو بھسم کرنے کا موقع نہ ہی کمرے میں پہنچیں تو مرسڈیز ہے وہ سمجھیں شروع ہوتا ہے وہ میری طرف پلٹی۔ میں بگھی کا شعلہ نکلتا ہے اور امی کا گیٹ کھول دیا۔ آپ نے انھیں ان ہوتا نہیں ایسے ہی میں جب کھانا کھانے کو کچھ سکے دئیے۔ بچو! علامہ اقبال نے سیٹھ کے کمرے کی تلاش کوئی جا رہے۔\n",
      "\n",
      "\n",
      "--- Generated Story 2 ---\n",
      "وہ واپس آتا میں ڈالی لئے مٹھو جیسا تو نہیں کیا کرنا نے ماں کو بھی یہ خوشبو بے وقوف نے ناریل کے گرنے آپ بڑی سال نہ رواں دواں ہو اور طالب علم جو کام خطرناک ہو وہ ہوا اور وہ بے ہوش پر خریدنے آیا۔ اتنے میں دوسرے بچے ، اسی لیے تھا۔ وہیں برسوں کی محنت چلاتے اور کسی مکھی نے جب چمگادڑ کا معمول میں تبدیلی کروگے؟ دیر گھی کی خوشبو اسے بے حد دُکھ کے ٹریننگ سینٹر غرض ہوتی ہیں، غریب کل رہا چلا ان کا بیٹا جو قرآن موضوعات ہیں کیوں بنا ہوا ہے؟ فائزہ نے جیسے ہی۔ لہٰذا میں نے یہ منظر آؤ، اندر آجاؤ۔ بہت خوب گیا واجد گھر میں خاصا وقت کر دیں، میں وعدہ کرتا اپنے بنائے ہوئے تھی۔ ڈاکٹر نے شہر کے بعد علیزے جاگ کی تمام ہاتھی رسیوں کے پاس کچھ بھی نوید۔ اہلکار نے پچھلے سال ان کے صبر پر کہا۔\n",
      "\n",
      "\n",
      "--- Generated Story 3 ---\n",
      "ٹرک ہم نے ان پرندوں کے ثناء کو کہا۔ ننھے بندر۔ توحید گھر تھا ہی کا کیاکرتے ہو۔ جہانگیر گیاجیسے میرے سر کی بجائے ابوذر نے سوال کیا اور جلد ہی سیکھ۔ امامہ آپی نے طاہر کو تاکید کردی جواب دیا، یہ تو دیکھا بیوی بولی نے بہت اچھے ہو کر بذریعہ فون ثمرہ کو بتا دیا کہ وہ سارے سیب توڑ دیا۔ شفیق یہ دستک جوکی نے اسے پانی پلایا اور اسکول بھیجا، لیکن یوسف نے اس لفافے میں سے کاغذ نکال کر دکھائے، تو وہ وہ ہمیں تاریک کمرے میں ہی تھا کہ بلند بخت آئے تھے، پہلے ہو گیا۔ طے اپنے پرانے ہی کیا آئے، جن پر رہتا یہاں کیسے لیا جاتا ہے۔\n",
      "\n",
      "\n",
      "✅ model.pkl saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "# -------------------------\n",
    "# 1️⃣ Load and clean corpus\n",
    "# -------------------------\n",
    "with open(\"corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Normalize text\n",
    "text = text.replace('', ' ')\n",
    "text = text.replace('\\n', ' ')\n",
    "text = ' '.join(text.split())\n",
    "\n",
    "# Split into sentences (roughly on Urdu full stop / question mark)\n",
    "sentences = [s.strip() for s in text.split('۔') if s.strip()]\n",
    "processed_sentences = []\n",
    "\n",
    "# Add <BOS> and <EOT> to each sentence\n",
    "for s in sentences:\n",
    "    tokens = s.split()\n",
    "    if tokens:\n",
    "        processed_sentences.append(['<BOS>', '<BOS>'] + tokens + ['<EOT>'])\n",
    "\n",
    "# Flatten all sentences for trigram counting\n",
    "all_tokens = [token for sentence in processed_sentences for token in sentence]\n",
    "\n",
    "# -------------------------\n",
    "# 2️⃣ Build n-gram counts\n",
    "# -------------------------\n",
    "unigrams = Counter(all_tokens)\n",
    "bigrams = Counter(zip(all_tokens[:-1], all_tokens[1:]))\n",
    "trigrams = Counter(zip(all_tokens[:-2], all_tokens[1:-1], all_tokens[2:]))\n",
    "\n",
    "vocab_size = len(unigrams)\n",
    "total_tokens = sum(unigrams.values())\n",
    "\n",
    "# -------------------------\n",
    "# 3️⃣ Interpolated trigram probability\n",
    "# -------------------------\n",
    "lambda1 = 0.2\n",
    "lambda2 = 0.3\n",
    "lambda3 = 0.5\n",
    "\n",
    "def interpolated_prob(w1, w2, w3):\n",
    "    # MLE probabilities\n",
    "    tri_count = trigrams.get((w1, w2, w3), 0)\n",
    "    bi_count = bigrams.get((w1, w2), 0)\n",
    "    bi_count2 = bigrams.get((w2, w3), 0)\n",
    "    uni_count = unigrams.get(w3, 0)\n",
    "    \n",
    "    p_tri = tri_count / bi_count if bi_count > 0 else 0\n",
    "    p_bi = bi_count2 / unigrams[w2] if unigrams[w2] > 0 else 0\n",
    "    p_uni = uni_count / total_tokens\n",
    "    \n",
    "    return lambda3*p_tri + lambda2*p_bi + lambda1*p_uni\n",
    "\n",
    "# -------------------------\n",
    "# 4️⃣ Generate one sentence\n",
    "# -------------------------\n",
    "def generate_sentence(max_words=50):\n",
    "    sentence = ['<BOS>', '<BOS>']\n",
    "    \n",
    "    for _ in range(max_words):\n",
    "        w1, w2 = sentence[-2], sentence[-1]\n",
    "        \n",
    "        candidates = list(unigrams.keys())\n",
    "        probs = [interpolated_prob(w1, w2, w3) for w3 in candidates]\n",
    "        total = sum(probs)\n",
    "        if total == 0:\n",
    "            break\n",
    "        probs = [p/total for p in probs]\n",
    "        \n",
    "        next_word = random.choices(candidates, probs)[0]\n",
    "        sentence.append(next_word)\n",
    "        \n",
    "        if next_word == '<EOT>':\n",
    "            break\n",
    "    \n",
    "    # Remove special tokens\n",
    "    sentence = [w for w in sentence if w not in ['<BOS>', '<EOT>']]\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "# -------------------------\n",
    "# 5️⃣ Generate full paragraph/story\n",
    "# -------------------------\n",
    "def generate_story(max_sentences=7):\n",
    "    story = []\n",
    "    for _ in range(max_sentences):\n",
    "        sent = generate_sentence()\n",
    "        if sent.strip():\n",
    "            story.append(sent + '۔')  # Urdu full stop\n",
    "    return ' '.join(story)\n",
    "\n",
    "# -------------------------\n",
    "# 6️⃣ Generate multiple stories\n",
    "# -------------------------\n",
    "for i in range(3):\n",
    "    print(f\"--- Generated Story {i+1} ---\")\n",
    "    print(generate_story(max_sentences=7))\n",
    "    print('\\n')\n",
    "    \n",
    "model_data = {\n",
    "    \"unigrams\": unigrams,\n",
    "    \"bigrams\": bigrams,\n",
    "    \"trigrams\": trigrams,\n",
    "    \"total_tokens\": total_tokens\n",
    "}\n",
    "\n",
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "print(\"model.pkl saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
